{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9b358d7-46ef-44cc-852f-c6011d0a2297",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Import et préparation des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35edaba8-0332-4400-af7c-f7a6081c2879",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Chargement et préparation des données\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"NYC_Taxi_Full\").getOrCreate()\n",
    "pop_path = \"/Workspace/dataTaxi/\"\n",
    "\n",
    "df_pop = spark.read.parquet(pop_path)\n",
    "\n",
    "df_pop.printSchema()\n",
    "df_pop.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed98aac3-2b07-4914-b5ba-ee1a9ed09363",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "files = dbutils.fs.ls(pop_path)\n",
    "\n",
    "df_list = []\n",
    "for f in files:\n",
    "    df_list.append(spark.read.parquet(f.path))\n",
    "\n",
    "df_pop = df_list[0]\n",
    "for df in df_list[1:]:\n",
    "    df_pop = df_pop.unionByName(df, allowMissingColumns=True)\n",
    "\n",
    "df_pop.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93c679eb-de11-4373-8f0d-4e5330ea0d1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e31d8e1a-395d-449c-98ae-e29799e95504",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, when, col\n",
    "\n",
    "null_summary = df_pop.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c)\n",
    "    for c in df_pop.columns\n",
    "])\n",
    "null_counts = null_summary.first().asDict()\n",
    "cols_with_nulls = [c for c, v in null_counts.items() if v > 0]\n",
    "\n",
    "print(\"Colonnes avec des valeurs nulles :\", cols_with_nulls)\n",
    "null_summary.select(cols_with_nulls).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "489397d3-088c-48d4-ab88-3001c02c2fa3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Lister uniquement les colonnes dont le type est 'long'\n",
    "long_columns = [field.name for field in df_pop.schema.fields if \"LongType\" in str(field.dataType)]\n",
    "print(\"Colonnes de type Long à convertir :\")\n",
    "print(long_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baea5089-4fd2-44dd-a1aa-2105373c55f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total_count = df_pop.count()\n",
    "distinct_count = df_pop.distinct().count()\n",
    "duplicate_count = total_count - distinct_count\n",
    "\n",
    "print(f\"Nombre total de lignes : {total_count:,}\")\n",
    "print(f\"Nombre de lignes en double : {duplicate_count:,}\")\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    df_pop.groupBy(df_pop.columns).count().filter(\"count > 1\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2572d58f-ee8c-4a22-8d5e-173e9ffeabd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Nettoyer valeurs manquantes et doublons** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fef5a4e6-d1c8-4b17-8dee-c06f9488cca2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "for c in long_columns:\n",
    "    df_pop = df_pop.withColumn(c, col(c).cast(\"double\"))\n",
    "df_pop = df_pop.dropDuplicates()\n",
    "df_pop = df_pop.fillna({\n",
    "    \"passenger_count\": 1.0,\n",
    "    \"RatecodeID\": 1.0,\n",
    "    \"congestion_surcharge\": 0.0,\n",
    "    \"airport_fee\": 0.0,\n",
    "    \"tip_amount\": 0.0,\n",
    "    \"tolls_amount\": 0.0,\n",
    "    \"store_and_fwd_flag\": \"N\"\n",
    "})\n",
    "df_final_clean = df_pop.filter(\n",
    "    (col(\"fare_amount\").between(2.5, 200)) & \n",
    "    (col(\"trip_distance\").between(0.1, 50)) & \n",
    "    (col(\"passenger_count\").between(1, 4))\n",
    ")\n",
    "\n",
    "print(f\"Nettoyage terminé ! Nombre de lignes finales : {df_final_clean.count():,}\")\n",
    "df_final_clean.select(\"fare_amount\", \"trip_distance\", \"passenger_count\").summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13b7adaf-97f9-47fb-a98b-827aea78b12c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_final_clean.limit(10)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "399caaa7-c831-4c1c-8e3f-a51933fc154d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Indicateurs Principaux**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e49af184-7967-493e-b194-8bacab3e3eeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stats_summary = df_final_clean.select(\"fare_amount\", \"trip_distance\", \"total_amount\", \"tip_amount\").summary()\n",
    "stats_summary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13a4a80b-71cc-4520-970e-f1209b463911",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prix moyen\n",
    "stats_pop = df_final_clean.select(\"fare_amount\").summary(\"mean\")\n",
    "stats_pop.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5094fbb-b4d3-4cf2-8419-7f469064de20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Distance moyenne\n",
    "distance_pop = df_final_clean.select(\"trip_distance\").summary(\"mean\")\n",
    "distance_pop.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd84fe35-bda1-4921-9777-8bb44a1605da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Durée moyenne\n",
    "from pyspark.sql.functions import unix_timestamp, avg\n",
    "df_duration = df_final_clean.withColumn(\"duration_min\", \n",
    "    (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\")) / 60)\n",
    "avg_duration_result = df_duration.select(avg(\"duration_min\")).alias(\"duree_moyenne\")\n",
    "avg_duration_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb335cab-2520-490a-9142-b0e53215bbc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Intervalle de Confiance\n",
    "import scipy.stats as st\n",
    "import math\n",
    "\n",
    "mean_fare = 18.1457\n",
    "stddev_fare = 16.5377\n",
    "n = 113619024  \n",
    "# l'erreur standard\n",
    "standard_error = stddev_fare / math.sqrt(n)\n",
    "\n",
    "# Intervalle de confiance à 95%\n",
    "confidence_interval = st.norm.interval(confidence=0.95, loc=mean_fare, scale=standard_error)\n",
    "\n",
    "print(f\"L'intervalle de confiance à 95% du prix moyen est : {confidence_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0df23246-353c-4217-8ee1-7f67155407ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Proportion des tips > 0\n",
    "total_trips = df_final_clean.count()\n",
    "trips_with_tip = df_final_clean.filter(\"tip_amount > 0\").count()\n",
    "proportion_tip = (trips_with_tip / total_trips) * 100\n",
    "\n",
    "print(f\"Nombre total de trajets : {total_trips}\")\n",
    "print(f\"Trajets avec pourboire : {trips_with_tip}\")\n",
    "print(f\"Proportion réelle : {proportion_tip:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e83fe40-1054-49c9-b34b-1d583a982f15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour, dayofweek, weekofyear, count\n",
    "\n",
    "# Heure \n",
    "dist_heure = df_final_clean.groupBy(hour(\"tpep_pickup_datetime\").alias(\"Heure\")) \\\n",
    "    .agg(count(\"*\").alias(\"Total_Courses\")) \\\n",
    "    .orderBy(\"Heure\")\n",
    "\n",
    "# Jour\n",
    "# (1 = Dimanche, 2 = Lundi, ..., 7 = Samedi)\n",
    "dist_jour = df_final_clean.groupBy(dayofweek(\"tpep_pickup_datetime\").alias(\"Jour\")) \\\n",
    "    .agg(count(\"*\").alias(\"Total_Courses\")) \\\n",
    "    .orderBy(\"Jour\")\n",
    "\n",
    "# Semaine \n",
    "dist_semaine = df_final_clean.groupBy(weekofyear(\"tpep_pickup_datetime\").alias(\"Semaine\")) \\\n",
    "    .agg(count(\"*\").alias(\"Total_Courses\")) \\\n",
    "    .orderBy(\"Semaine\")\n",
    "print(\"--- Distribution par Heure ---\")\n",
    "dist_heure.show(24)\n",
    "print(\"--- Distribution par Jour (1=Dim, 7=Sam) ---\")\n",
    "dist_jour.show()\n",
    "print(\"--- Distribution par Semaine de l'année ---\")\n",
    "dist_semaine.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff8c1f99-71fc-40b3-baab-4efec0a97548",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "diversity_stats = df_final_clean.select(countDistinct(\"PULocationID\").alias(\"nb_zones\")).collect()[0][0]\n",
    "\n",
    "#(Top 10 zones les plus chères)\n",
    "fares_by_zone = df_final_clean.groupBy(\"PULocationID\") \\\n",
    "    .agg(avg(\"fare_amount\").alias(\"avg_fare\")) \\\n",
    "    .orderBy(\"avg_fare\", ascending=False)\n",
    "\n",
    "print(f\"Nombre total de zones géographiques couvertes : {diversity_stats}\")\n",
    "fares_by_zone.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8664b5fd-b7c5-4b99-bd0a-aeaea849148e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Valeur des valeurs maximales et minimales de la valeur et de la distance\n",
    "outliers_stats = df_final_clean.select(\"fare_amount\", \"trip_distance\").summary(\"min\", \"max\", \"50%\", \"95%\", \"99%\")\n",
    "outliers_stats.show()\n",
    "\n",
    "#Le comptage du nombre de voyages coûtant plus de 200 dollars est un exemple de valeurs aberrantes.\n",
    "expensive_trips = df_final_clean.filter(\"fare_amount > 200\").count()\n",
    "print(f\"Le nombre de voyages qui coûtent plus de 200 $ est : {expensive_trips}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c50ffd5-3f48-4e2e-82ed-3a948ae75406",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, avg, when\n",
    "\n",
    "tip_analysis = df_final_clean.filter(\"fare_amount > 0 AND payment_type IN (1, 2)\") \\\n",
    "    .groupBy(\"payment_type\") \\\n",
    "    .agg(avg(col(\"tip_amount\") / col(\"fare_amount\")).alias(\"tip_ratio_moyen\"))\n",
    "tip_analysis_named = tip_analysis.withColumn(\"payment_method\", \n",
    "    when(col(\"payment_type\") == 1, \"Carte Bancaire\").otherwise(\"Cash\"))\n",
    "\n",
    "tip_analysis_named.select(\"payment_method\", \"tip_ratio_moyen\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Analyse Big Data – Population Complète (100%)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
